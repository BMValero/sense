#!/usr/bin/env python
"""
The annotation script allows you to annotate the frames generated by `prepare_annotation.py` for a given class and
split in the data-set folder.

Usage:
  annotation.py --data_path=DATA_PATH --split=SPLIT --label=LABEL
  annotation.py (-h | --help)

Options:
  --data_path=DATA_PATH     Complete or relative path to the data-set folder
  --split=SPLIT             Type of split to collect videos from, either `train` or `valid`
  --label=LABEL             Class-label to get the videos for annotation
"""


import glob
import json
import numpy as np
import os

from docopt import docopt
from flask import Flask
from flask import redirect
from flask import render_template
from flask import request
from flask import send_from_directory
from flask import url_for
from joblib import dump
from joblib import load
from os.path import join
from sklearn.linear_model import LogisticRegression


app = Flask(__name__)
app.secret_key = 'd66HR8dç"f_-àgjYYic*dh'


def extension_ok(nomfic):
    """ Returns `True` if the file has a valid image extension. """
    return '.' in nomfic and nomfic.rsplit('.', 1)[1] in ('png', 'jpg', 'jpeg', 'gif', 'bmp')


@app.route('/annot/')
def list_annot():
    """Gets the data and creates the HTML template with all videos for the given class-label."""
    folder_id = zip(videos, list(range(len(videos))))
    return render_template('up_folder.html', folders=folder_id)


@app.route('/annot/<nom>')
def annot(nom):
    """For the given class-label, this shows all the frames for annotating the selected video."""
    nom = int(nom)
    features = np.load(join(features_dir, videos[nom] + ".npy"))
    features = features.mean(axis=(2, 3))

    if lr is not None:
        classes = list(lr.predict(features))
    else:
        classes = [0] * len(features)
    print(classes)

    # The list of images in the folder
    images = [img for img in glob.glob(join(frames_dir, videos[nom] + '/*')) if extension_ok(img)]
    
    nums = [int(x.split('.')[0].split('/')[-1]) for x in images]
    n_images = len(nums)
    images = [[x.replace(frames_dir, ''), y] for y, x in sorted(zip(nums, images))]
    images = [[x[0], x[1], y] for x, y in zip(images, classes)]
    chunk_size = 5
    images = np.array_split(images, np.arange(chunk_size, len(images), chunk_size))
    images = [list(x) for x in images]
    print(f"Number of images: {n_images}")
    print(images)
    return render_template('up_liste.html', images=images, num=nom, fps=16, n_images=n_images, video_name=videos[nom])


@app.route('/response', methods=['POST'])
def response():
    if request.method == 'POST':
        data = request.form                 # a multi-dict containing POST data
        num = int(data['num'])
        fps = float(data['fps'])
        next_frame_num = num+1
        description = {'file': videos[num] + ".mp4", 'fps': fps}
        out_annotation = os.path.join(tags_dir, videos[num] + ".json")
        time_annotation = []
        for i in range(int(data['n_images'])):
            time_annotation.append(int(data[str(i)]))
        description['time_annotation'] = time_annotation
        json.dump(description, open(out_annotation, 'w'))
        if next_frame_num >= len(videos):
            return redirect(url_for('list_annot'))
    return redirect(url_for('annot', nom=next_frame_num))


@app.route('/train_lr', methods=['POST'])
def train_lr():
    global lr
    if request.method == 'POST':
        data = request.form  # a multi-dict containing POST data
        num = int(data['num'])
        annotations = os.listdir(tags_dir)
        class_weight = {0: 0.5}
        if annotations:
            features = [join(features_dir, x.replace('.json', '.npy')) for x in annotations]
            annotations = [join(tags_dir, x) for x in annotations]
            X = []
            y = []
            for feature in features:
                feature = np.load(feature)
                for f in feature:
                    X.append(f.mean(axis=(1, 2)))
            for annotation in annotations:
                annotation = json.load(open(annotation, 'r'))['time_annotation']
                pos1 = np.where(np.array(annotation).astype(int) == 1)[0]
                if len(pos1) > 0:
                    class_weight.update({1: 2})
                    for p in pos1:
                        try:
                            annotation[p + 1] = 1
                        except:
                            1
                pos1 = np.where(np.array(annotation).astype(int) == 2)[0]
                if len(pos1) > 0:
                    class_weight.update({2: 2})
                    for p in pos1:
                        try:
                            annotation[p + 1] = 2
                        except:
                            1
                for a in annotation:
                    y.append(a)
            X = np.array(X)
            print(X.shape)
            y = np.array(y)
            lr = LogisticRegression(C=0.1, class_weight=class_weight)
            lr.fit(X, y)
            dump(lr, lr_path)
    return redirect(url_for('annot', nom=num))



@app.after_request
def add_header(r):
    """
    Add headers to both force latest IE rendering engine or Chrome Frame,
    and also to cache the rendered page for 10 minutes.
    """
    r.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
    r.headers["Pragma"] = "no-cache"
    r.headers["Expires"] = "0"
    r.headers['Cache-Control'] = 'public, max-age=0'
    return r


@app.route('/uploads/<path:filename>')
def download_file(filename):
    return send_from_directory(frames_dir, filename, as_attachment=True)


if __name__ == '__main__':
    # Parse arguments
    args = docopt(__doc__)
    dataset_path = args['--data_path']
    split = args['--split']
    label = args['--label']

    folder = os.path.join(dataset_path, f'videos_{split}', label)
    features_dir = dataset_path + f"features_{split}/{label}/"
    frames_dir = dataset_path + f"frames_{split}/{label}/"
    tags_dir = dataset_path + f"tags_{split}/{label}/"
    lr_dir = join(dataset_path, 'lr', label)
    os.makedirs(lr_dir, exist_ok=True)
    os.makedirs(tags_dir, exist_ok=True)

    videos = os.listdir(frames_dir)
    videos.sort()

    lr = None
    lr_path = join(lr_dir, 'lr.joblib')
    if os.path.isfile(lr_path):
        lr = load(lr_path)

    app.run(debug=True)
